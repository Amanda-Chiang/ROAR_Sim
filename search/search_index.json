{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Technical Documentation for ROAR-Simulator Note: For more information regarding DeCal Course visit Roar Decal . Getting Started We use Carla which is an open-source simulator for autonomous driving research as our main demonstration of autonomous racing during COVID-19. If you are new to the project visit GetingStarted If you are curious about ROAR Competition at Berkeley visit BerkeleyROAR If you are curious about Carla visit CarlaSimulator","title":"Home"},{"location":"#technical-documentation-for-roar-simulator","text":"Note: For more information regarding DeCal Course visit Roar Decal .","title":"Technical Documentation for ROAR-Simulator"},{"location":"#getting-started","text":"We use Carla which is an open-source simulator for autonomous driving research as our main demonstration of autonomous racing during COVID-19. If you are new to the project visit GetingStarted If you are curious about ROAR Competition at Berkeley visit BerkeleyROAR If you are curious about Carla visit CarlaSimulator","title":"Getting Started"},{"location":"code_documentations/bridges/","text":"","title":"Bridges"},{"location":"code_documentations/roar_autonomous_system/agents/","text":"Documentation for Agents ROAR_simulation.roar_autonomous_system.agent_module.agent.Agent Abstract Agent class that define the minimum of a ROAR agent. Inherited agent can perform different duties. Methods __init__ ( self , vehicle , front_rgb_camera = None , front_depth_camera = None , rear_rgb_camera = None , imu = None ) special Initiating the Agent with given vehicle, front and back RGB cameras, front depth camera and IMU sensor Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( self , vehicle : Vehicle , front_rgb_camera : Optional [ Camera ] = None , front_depth_camera : Optional [ Camera ] = None , rear_rgb_camera : Optional [ Camera ] = None , imu : Optional [ IMUData ] = None ): \"\"\"Initiating the Agent with given vehicle, front and back RGB cameras, front depth camera and IMU sensor\"\"\" self . vehicle = vehicle self . front_rgb_camera = front_rgb_camera self . front_depth_camera = front_depth_camera self . rear_rgb_camera = rear_rgb_camera self . init_cam () self . imu = imu self . logger = logging . getLogger ( __name__ ) self . transform_history : List [ Transform ] = [] init_cam ( self ) Calculate intrinsic matrices for each existing camera (front/back RGB and front depth). Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 37 38 39 40 41 42 43 44 45 def init_cam ( self ): \"\"\"Calculate intrinsic matrices for each existing camera (front/back RGB and front depth). \"\"\" if self . front_rgb_camera is not None : self . front_rgb_camera . intrinsics_matrix = self . front_rgb_camera . calculate_intrinsic_matrix () if self . front_depth_camera is not None : self . front_depth_camera . intrinsics_matrix = self . front_depth_camera . calculate_intrinsic_matrix () if self . rear_rgb_camera is not None : self . rear_rgb_camera . intrinsics_matrix = self . rear_rgb_camera . calculate_intrinsic_matrix () run_step ( self , sensors_data , vehicle ) Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : \"\"\" Receive Sensor Data and vehicle state information on every step and return a control Args: sensors_data: sensor data on this frame vehicle: vehicle state on this frame Returns: Vehicle Control \"\"\" self . sync_data ( sensors_data = sensors_data , vehicle = vehicle ) return VehicleControl () sync_data ( self , sensors_data , vehicle ) Syncing the data from cameras with the ROAR Agent's camera data. Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def sync_data ( self , sensors_data : SensorsData , vehicle : Vehicle ): \"\"\"Syncing the data from cameras with the ROAR Agent's camera data. \"\"\" self . vehicle = vehicle if self . front_rgb_camera is not None : self . front_rgb_camera . data = sensors_data . front_rgb . data if sensors_data . front_rgb is not None else None if self . front_depth_camera is not None : self . front_depth_camera . data = sensors_data . front_depth . data if sensors_data . front_depth is not None else None if self . rear_rgb_camera is not None : self . rear_rgb_camera . data = sensors_data . rear_rgb . data if sensors_data . rear_rgb is not None else None if self . imu is not None : self . imu = sensors_data . imu_data ROAR_simulation.roar_autonomous_system.agent_module.purpursuit_agent.PurePursuitAgent Methods __init__ ( self , vehicle , route_file_path ) special Source code in ROAR_simulation/roar_autonomous_system/agent_module/purpursuit_agent.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , vehicle : Vehicle , route_file_path : Path ): super () . __init__ ( vehicle ) self . route_file_path = route_file_path self . pure_pursuit_controller = PurePursuitController ( vehicle = vehicle , target_speed = 150 , look_ahead_gain = 0.1 , look_ahead_distance = 1 ) self . mission_planner = WaypointFollowingMissionPlanner ( file_path = self . route_file_path , vehicle = vehicle ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( vehicle = vehicle ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( vehicle = vehicle , controller = self . pure_pursuit_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 1 ) self . visualizer = Visualizer ( agent = self ) run_step ( self , sensors_data , vehicle ) Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/purpursuit_agent.py 34 35 36 def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super ( PurePursuitAgent , self ) . run_step ( sensors_data = sensors_data , vehicle = vehicle ) return self . local_planner . run_step ( vehicle = vehicle ) ROAR_simulation.roar_autonomous_system.agent_module.semantic_segmentation_agent.SemanticSegmentationAgent Methods __init__ ( self , vehicle , front_depth_camera , show_gpd_data = False ) special Source code in ROAR_simulation/roar_autonomous_system/agent_module/semantic_segmentation_agent.py 13 14 15 16 17 18 19 20 21 22 23 24 25 def __init__ ( self , vehicle : Vehicle , front_depth_camera : Camera , show_gpd_data = False ): super () . __init__ ( vehicle = vehicle , front_depth_camera = front_depth_camera ) self . semantic_seg_detector = SemanticSegmentationDetector ( vehicle = vehicle , camera = self . front_depth_camera ) self . controller = VehiclePIDController ( self . vehicle , args_lateral = PIDParam . default_lateral_param (), args_longitudinal = PIDParam . default_longitudinal_param (), target_speed = 40 ) self . local_planner = SemanticSegmentationOnlyPlanner ( vehicle = self . vehicle , controller = self . controller , gpd_detector = self . semantic_seg_detector , next_waypoint_distance = 10 , max_turn_degree = 10 ) self . visualizer = Visualizer ( agent = self ) run_step ( self , vehicle , sensors_data ) Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/semantic_segmentation_agent.py 27 28 29 30 31 32 33 def run_step ( self , vehicle : Vehicle , sensors_data : SensorsData ) -> VehicleControl : super ( SemanticSegmentationAgent , self ) . run_step ( vehicle = vehicle , sensors_data = sensors_data ) self . semantic_seg_detector . run_step ( vehicle = vehicle , new_data = sensors_data . front_depth . data ) control = self . local_planner . run_step ( vehicle = vehicle ) self . visualizer . visualize_semantic_segmentation ( semantic_segmetation = self . semantic_seg_detector . semantic_segmentation ) return control ROAR_simulation.roar_autonomous_system.agent_module.waypoint_following_agent.WaypointFollowingAgent Methods __init__ ( self , vehicle , route_file_path , target_speed = 40 , ** kwargs ) special Source code in ROAR_simulation/roar_autonomous_system/agent_module/waypoint_following_agent.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def __init__ ( self , vehicle , route_file_path : Path , target_speed = 40 , ** kwargs ): super () . __init__ ( vehicle , ** kwargs ) self . logger = logging . getLogger ( \"PathFollowingAgent\" ) self . route_file_path = route_file_path self . pid_controller = VehiclePIDController ( vehicle = vehicle , args_lateral = PIDParam . default_lateral_param (), args_longitudinal = PIDParam . default_longitudinal_param (), target_speed = target_speed ) self . mission_planner = WaypointFollowingMissionPlanner ( file_path = self . route_file_path , vehicle = vehicle ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( vehicle = vehicle ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( vehicle = vehicle , controller = self . pid_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 1 ) self . visualizer = Visualizer ( agent = self ) self . logger . debug ( f \"Waypoint Following Agent Initiated. Reading from { route_file_path . as_posix () } \" ) self . curr_max_err = 0 self . counter = 0 self . total_err = 0 run_step ( self , vehicle , sensors_data ) Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/waypoint_following_agent.py 40 41 42 43 44 45 46 47 48 def run_step ( self , vehicle : Vehicle , sensors_data : SensorsData ) -> VehicleControl : super ( WaypointFollowingAgent , self ) . run_step ( vehicle = vehicle , sensors_data = sensors_data ) self . transform_history . append ( self . vehicle . transform ) if self . local_planner . is_done (): control = VehicleControl () self . logger . debug ( \"Path Following Agent is Done. Idling.\" ) else : control = self . local_planner . run_step ( vehicle = vehicle ) return control","title":"Agents"},{"location":"code_documentations/roar_autonomous_system/agents/#documentation-for-agents","text":"","title":"Documentation for Agents"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.agent.Agent","text":"Abstract Agent class that define the minimum of a ROAR agent. Inherited agent can perform different duties.","title":"Agent"},{"location":"code_documentations/roar_autonomous_system/agents/#methods","text":"","title":"Methods"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.agent.Agent.__init__","text":"Initiating the Agent with given vehicle, front and back RGB cameras, front depth camera and IMU sensor Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def __init__ ( self , vehicle : Vehicle , front_rgb_camera : Optional [ Camera ] = None , front_depth_camera : Optional [ Camera ] = None , rear_rgb_camera : Optional [ Camera ] = None , imu : Optional [ IMUData ] = None ): \"\"\"Initiating the Agent with given vehicle, front and back RGB cameras, front depth camera and IMU sensor\"\"\" self . vehicle = vehicle self . front_rgb_camera = front_rgb_camera self . front_depth_camera = front_depth_camera self . rear_rgb_camera = rear_rgb_camera self . init_cam () self . imu = imu self . logger = logging . getLogger ( __name__ ) self . transform_history : List [ Transform ] = []","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.agent.Agent.init_cam","text":"Calculate intrinsic matrices for each existing camera (front/back RGB and front depth). Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 37 38 39 40 41 42 43 44 45 def init_cam ( self ): \"\"\"Calculate intrinsic matrices for each existing camera (front/back RGB and front depth). \"\"\" if self . front_rgb_camera is not None : self . front_rgb_camera . intrinsics_matrix = self . front_rgb_camera . calculate_intrinsic_matrix () if self . front_depth_camera is not None : self . front_depth_camera . intrinsics_matrix = self . front_depth_camera . calculate_intrinsic_matrix () if self . rear_rgb_camera is not None : self . rear_rgb_camera . intrinsics_matrix = self . rear_rgb_camera . calculate_intrinsic_matrix ()","title":"init_cam()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.agent.Agent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : \"\"\" Receive Sensor Data and vehicle state information on every step and return a control Args: sensors_data: sensor data on this frame vehicle: vehicle state on this frame Returns: Vehicle Control \"\"\" self . sync_data ( sensors_data = sensors_data , vehicle = vehicle ) return VehicleControl ()","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.agent.Agent.sync_data","text":"Syncing the data from cameras with the ROAR Agent's camera data. Source code in ROAR_simulation/roar_autonomous_system/agent_module/agent.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def sync_data ( self , sensors_data : SensorsData , vehicle : Vehicle ): \"\"\"Syncing the data from cameras with the ROAR Agent's camera data. \"\"\" self . vehicle = vehicle if self . front_rgb_camera is not None : self . front_rgb_camera . data = sensors_data . front_rgb . data if sensors_data . front_rgb is not None else None if self . front_depth_camera is not None : self . front_depth_camera . data = sensors_data . front_depth . data if sensors_data . front_depth is not None else None if self . rear_rgb_camera is not None : self . rear_rgb_camera . data = sensors_data . rear_rgb . data if sensors_data . rear_rgb is not None else None if self . imu is not None : self . imu = sensors_data . imu_data","title":"sync_data()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.purpursuit_agent.PurePursuitAgent","text":"","title":"PurePursuitAgent"},{"location":"code_documentations/roar_autonomous_system/agents/#methods_1","text":"","title":"Methods"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.purpursuit_agent.PurePursuitAgent.__init__","text":"Source code in ROAR_simulation/roar_autonomous_system/agent_module/purpursuit_agent.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , vehicle : Vehicle , route_file_path : Path ): super () . __init__ ( vehicle ) self . route_file_path = route_file_path self . pure_pursuit_controller = PurePursuitController ( vehicle = vehicle , target_speed = 150 , look_ahead_gain = 0.1 , look_ahead_distance = 1 ) self . mission_planner = WaypointFollowingMissionPlanner ( file_path = self . route_file_path , vehicle = vehicle ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( vehicle = vehicle ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( vehicle = vehicle , controller = self . pure_pursuit_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 1 ) self . visualizer = Visualizer ( agent = self )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.purpursuit_agent.PurePursuitAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/purpursuit_agent.py 34 35 36 def run_step ( self , sensors_data : SensorsData , vehicle : Vehicle ) -> VehicleControl : super ( PurePursuitAgent , self ) . run_step ( sensors_data = sensors_data , vehicle = vehicle ) return self . local_planner . run_step ( vehicle = vehicle )","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.semantic_segmentation_agent.SemanticSegmentationAgent","text":"","title":"SemanticSegmentationAgent"},{"location":"code_documentations/roar_autonomous_system/agents/#methods_2","text":"","title":"Methods"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.semantic_segmentation_agent.SemanticSegmentationAgent.__init__","text":"Source code in ROAR_simulation/roar_autonomous_system/agent_module/semantic_segmentation_agent.py 13 14 15 16 17 18 19 20 21 22 23 24 25 def __init__ ( self , vehicle : Vehicle , front_depth_camera : Camera , show_gpd_data = False ): super () . __init__ ( vehicle = vehicle , front_depth_camera = front_depth_camera ) self . semantic_seg_detector = SemanticSegmentationDetector ( vehicle = vehicle , camera = self . front_depth_camera ) self . controller = VehiclePIDController ( self . vehicle , args_lateral = PIDParam . default_lateral_param (), args_longitudinal = PIDParam . default_longitudinal_param (), target_speed = 40 ) self . local_planner = SemanticSegmentationOnlyPlanner ( vehicle = self . vehicle , controller = self . controller , gpd_detector = self . semantic_seg_detector , next_waypoint_distance = 10 , max_turn_degree = 10 ) self . visualizer = Visualizer ( agent = self )","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.semantic_segmentation_agent.SemanticSegmentationAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/semantic_segmentation_agent.py 27 28 29 30 31 32 33 def run_step ( self , vehicle : Vehicle , sensors_data : SensorsData ) -> VehicleControl : super ( SemanticSegmentationAgent , self ) . run_step ( vehicle = vehicle , sensors_data = sensors_data ) self . semantic_seg_detector . run_step ( vehicle = vehicle , new_data = sensors_data . front_depth . data ) control = self . local_planner . run_step ( vehicle = vehicle ) self . visualizer . visualize_semantic_segmentation ( semantic_segmetation = self . semantic_seg_detector . semantic_segmentation ) return control","title":"run_step()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.waypoint_following_agent.WaypointFollowingAgent","text":"","title":"WaypointFollowingAgent"},{"location":"code_documentations/roar_autonomous_system/agents/#methods_3","text":"","title":"Methods"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.waypoint_following_agent.WaypointFollowingAgent.__init__","text":"Source code in ROAR_simulation/roar_autonomous_system/agent_module/waypoint_following_agent.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def __init__ ( self , vehicle , route_file_path : Path , target_speed = 40 , ** kwargs ): super () . __init__ ( vehicle , ** kwargs ) self . logger = logging . getLogger ( \"PathFollowingAgent\" ) self . route_file_path = route_file_path self . pid_controller = VehiclePIDController ( vehicle = vehicle , args_lateral = PIDParam . default_lateral_param (), args_longitudinal = PIDParam . default_longitudinal_param (), target_speed = target_speed ) self . mission_planner = WaypointFollowingMissionPlanner ( file_path = self . route_file_path , vehicle = vehicle ) # initiated right after mission plan self . behavior_planner = BehaviorPlanner ( vehicle = vehicle ) self . local_planner = SimpleWaypointFollowingLocalPlanner ( vehicle = vehicle , controller = self . pid_controller , mission_planner = self . mission_planner , behavior_planner = self . behavior_planner , closeness_threshold = 1 ) self . visualizer = Visualizer ( agent = self ) self . logger . debug ( f \"Waypoint Following Agent Initiated. Reading from { route_file_path . as_posix () } \" ) self . curr_max_err = 0 self . counter = 0 self . total_err = 0","title":"__init__()"},{"location":"code_documentations/roar_autonomous_system/agents/#ROAR_simulation.roar_autonomous_system.agent_module.waypoint_following_agent.WaypointFollowingAgent.run_step","text":"Receive Sensor Data and vehicle state information on every step and return a control Parameters: Name Type Description Default sensors_data SensorsData sensor data on this frame required vehicle Vehicle vehicle state on this frame required Returns: Type Description VehicleControl Vehicle Control Source code in ROAR_simulation/roar_autonomous_system/agent_module/waypoint_following_agent.py 40 41 42 43 44 45 46 47 48 def run_step ( self , vehicle : Vehicle , sensors_data : SensorsData ) -> VehicleControl : super ( WaypointFollowingAgent , self ) . run_step ( vehicle = vehicle , sensors_data = sensors_data ) self . transform_history . append ( self . vehicle . transform ) if self . local_planner . is_done (): control = VehicleControl () self . logger . debug ( \"Path Following Agent is Done. Idling.\" ) else : control = self . local_planner . run_step ( vehicle = vehicle ) return control","title":"run_step()"},{"location":"getting_started/quick_start/","text":"ROAR Carla Simulation QuickStart Required Equipment: Linux/Windows Computer Approximate Time: 15 minutes Download the this code here [as of writing this readme, we still need to create a public github repo] Download the right distribution of Carla for your Operation System here You should download either roar_easy_linux.zip or roar_easy_windows.zip Initiate a virtual environment. conda create -n ROAR python=3.7 conda activate ROAR Install required packages pip install -r requirements.txt You are all set up. Start the server on Windows, you may double click the CarlaUE4.exe or you may use a commandline prompt and type in CarlaUE4.exe on Ubuntu, you can directly type ./CarlaUE4.sh Start Client connection python carla_runner.py You should be on manual control now. To switch to autonomous mode, open up carla_runner.py and scroll down the end, change the line `settings.enable_aut Common Errors Conda not found You should download miniconda3 Linux/Windows 64-bit miniconda3 Follow the below instructions to install miniconda successfully If still cannot call conda, try (directory may vary): sudo chown -R /home/username/miniconda3/' sudo chmod -R +x /home/username/miniconda3/","title":"Setup"},{"location":"getting_started/quick_start/#roar-carla-simulation","text":"","title":"ROAR Carla Simulation"},{"location":"getting_started/quick_start/#quickstart","text":"Required Equipment: Linux/Windows Computer Approximate Time: 15 minutes Download the this code here [as of writing this readme, we still need to create a public github repo] Download the right distribution of Carla for your Operation System here You should download either roar_easy_linux.zip or roar_easy_windows.zip Initiate a virtual environment. conda create -n ROAR python=3.7 conda activate ROAR Install required packages pip install -r requirements.txt You are all set up. Start the server on Windows, you may double click the CarlaUE4.exe or you may use a commandline prompt and type in CarlaUE4.exe on Ubuntu, you can directly type ./CarlaUE4.sh Start Client connection python carla_runner.py You should be on manual control now. To switch to autonomous mode, open up carla_runner.py and scroll down the end, change the line `settings.enable_aut","title":"QuickStart"},{"location":"getting_started/quick_start/#common-errors","text":"Conda not found You should download miniconda3 Linux/Windows 64-bit miniconda3 Follow the below instructions to install miniconda successfully If still cannot call conda, try (directory may vary): sudo chown -R /home/username/miniconda3/' sudo chmod -R +x /home/username/miniconda3/","title":"Common Errors"},{"location":"lectures_folder/3DPrint/","text":"3D Printing","title":"3DPrint"},{"location":"lectures_folder/A%26JN/","text":"Arduino Lecture PPT Jetson Nano PPt","title":"A&JN"},{"location":"lectures_folder/CV/","text":"Localization PPT","title":"CV"},{"location":"lectures_folder/PID/","text":"Virtual Reality Racing","title":"PID"},{"location":"project_overview/code_layout/","text":"ROAR bridges - Sync data between different sources and Agent carla_client - Custimized Module responsible for initializing and communicating with the Carla Server roar_autonomous_system agent_module - Declaration and implementation of different Agents control_module - Declaration and implementation of different Controllers perception_module - Declaration and implementation of different Detectors planning_module - Declaration and implementation of different Planning algorithms utilities_module - Declaration of useful data structures visualization_module - Centralized Visualization functions readme.md requirements.txt runner.py","title":"Code Layout"},{"location":"project_overview/project_module_TADs/","text":"ROAR Carla Overall Architecture Environment Maps Environmental Perception Motion Planning Vehicle Controller","title":"Project Module TAD"},{"location":"project_overview/project_module_TADs/#roar-carla-overall-architecture","text":"","title":"ROAR Carla Overall Architecture"},{"location":"project_overview/project_module_TADs/#environment-maps","text":"","title":"Environment Maps"},{"location":"project_overview/project_module_TADs/#environmental-perception","text":"","title":"Environmental Perception"},{"location":"project_overview/project_module_TADs/#motion-planning","text":"","title":"Motion Planning"},{"location":"project_overview/project_module_TADs/#vehicle-controller","text":"","title":"Vehicle Controller"}]}